{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "revolutionary-barbados",
   "metadata": {},
   "source": [
    "# Running SageMaker Studio Notebooks Remotely via API\n",
    "\n",
    "This notebook demonstrates use of the [JupyterServer API](https://github.com/jupyter/jupyter/wiki/Jupyter-Notebook-Server-API#Kernel-API) and the [Jupyter Client (websocket) API](https://jupyter-client.readthedocs.io/en/latest/messaging.html) to remotely run commands on (specifically, 'all the code cells of') a notebook in SageMaker Studio.\n",
    "\n",
    "It's presented as a notebook to give more space for commentary, and because I used a SageMaker Notebook Instance in the same AWS region to test it out üòÅ ...But you could re-purpose the same code in some other environment (like a Lambda function) to run whatever automations you need.\n",
    "\n",
    "The main constraint is that your execution environment **needs IAM permission** `sagemaker:CreatePresignedDomainUrl` on the target `DomainId` and `UserProfileName` - which lets this script **log in as the SageMaker Studio user** to run the commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frank-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import requests\n",
    "import websocket\n",
    "\n",
    "smclient = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-gibson",
   "metadata": {},
   "source": [
    "## Log in\n",
    "\n",
    "For access to the APIs, we'll need to:\n",
    "\n",
    "- Generate the initial presigned login URL via SageMaker API\n",
    "- Open a `requests.session` to persist the headers/cookies/etc that get set when we first open the URL and then make requests\n",
    "- Remember to set the required **cross-site request forgery protection token** from cookies, on update request types like `POST`, `DELETE`, etc (if you're not familiar with this CSRF/XSRF protection mechanism, you can read more [here](https://en.wikipedia.org/wiki/Cross-site_request_forgery#Cookie-to-header_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://d-ngfhxewhrmqe.studio.ap-southeast-1.sagemaker.aws/jupyter/default\n"
     ]
    }
   ],
   "source": [
    "# Generate the presigned URL which facilitates login:\n",
    "presigned_resp = smclient.create_presigned_domain_url(\n",
    "    DomainId=\"d-YOUR-DOMAIN-ID-HERE\",\n",
    "    UserProfileName=\"YOUR-TARGET-USER-PROFILE-NAME-HERE\",\n",
    ")\n",
    "\n",
    "# Login like https://d-....studio.{AWSRegion}.sagemaker.aws/auth?token=...\n",
    "login_url = presigned_resp[\"AuthorizedUrl\"]\n",
    "# API relative to https://d-....studio.{AWSRegion}.sagemaker.aws/jupyter/default\n",
    "api_base_url = login_url.partition(\"?\")[0].rpartition(\"/\")[0] + \"/jupyter/default\"\n",
    "print(api_base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frozen-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Create an HTTP session (for cookie/header memory) and use it to log in:\n",
    "reqsess = requests.Session()\n",
    "login_resp = reqsess.get(presigned_resp[\"AuthorizedUrl\"])\n",
    "print(login_resp)\n",
    "\n",
    "# (See login_resp.headers and login_resp.text (the loading page HTML) for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chronic-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to wait here if the JupyterServer 'default' app is not ready?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-ghost",
   "metadata": {},
   "source": [
    "## Find & load your target notebook file\n",
    "\n",
    "This example hard-codes the notebook name to avoid accidentally executing something it shouldn't - but in general you'll want to use the `contents` APIs to locate your target notebook file, check it exists, or even upload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "palestinian-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"\",\n",
      "  \"path\": \"\",\n",
      "  \"last_modified\": \"2021-04-16T11:24:54.112000Z\",\n",
      "  \"created\": \"2021-04-16T11:24:54.112000Z\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"name\": \"HelloWorld.json\",\n",
      "      \"path\": \"HelloWorld.json\",\n",
      "      \"last_modified\": \"2021-04-16T14:48:36.411000Z\",\n",
      "      \"created\": \"2021-04-16T14:48:36.411000Z\",\n",
      "      \"content\": null,\n",
      "      \"format\": null,\n",
      "      \"mimetype\": \"application/json\",\n",
      "      \"size\": 7,\n",
      "      \"writable\": true,\n",
      "      \"type\": \"file\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"HelloWorld.ipynb\",\n",
      "      \"path\": \"HelloWorld.ipynb\",\n",
      "      \"last_modified\": \"2021-04-16T08:59:53.550000Z\",\n",
      "      \"created\": \"2021-04-16T08:59:53.550000Z\",\n",
      "      \"content\": null,\n",
      "      \"format\": null,\n",
      "      \"mimetype\": null,\n",
      "      \"size\": 1078,\n",
      "      \"writable\": true,\n",
      "      \"type\": \"notebook\"\n",
      "    }\n",
      "  ],\n",
      "  \"format\": \"json\",\n",
      "  \"mimetype\": null,\n",
      "  \"size\": null,\n",
      "  \"writable\": true,\n",
      "  \"type\": \"directory\"\n",
      "}\n",
      "\n",
      "Found HelloWorld.ipynb\n"
     ]
    }
   ],
   "source": [
    "# We'll hard-code the notebook URI below, but there are also APIs to traverse the directories:\n",
    "contents_resp = reqsess.get(f\"{api_base_url}/api/contents\").json()\n",
    "\n",
    "nbpath = \"HelloWorld.ipynb\"\n",
    "nbname = nbpath\n",
    "\n",
    "print(json.dumps(contents_resp, indent=2))\n",
    "\n",
    "# Check the notebook exists at the top level of the folder tree:\n",
    "try:\n",
    "    next(\n",
    "        c for c in contents_resp[\"content\"]\n",
    "        if c[\"type\"] == \"notebook\" # not 'file' or 'directory'\n",
    "        and c[\"name\"] == nbname\n",
    "        and c[\"path\"] == nbpath\n",
    "    )\n",
    "    print(f\"\\nFound {nbpath}\")\n",
    "except StopIteration:\n",
    "    raise ValueError(f\"Could not find {nbpath} in the user's account!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-width",
   "metadata": {},
   "source": [
    "Next, you'll want to load the contents of the target file because it contains the code to execute, but also specifies the kernel we'll need to run it on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "northern-beach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HelloWorld.ipynb\n",
      "Kernel spec:\n",
      "{'display_name': 'Python 3 (Data Science)', 'language': 'python', 'name': 'python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0'}\n",
      "\n",
      "Loaded 3 cells of code\n"
     ]
    }
   ],
   "source": [
    "# Load the notebook and get the code of each cell\n",
    "print(f\"Loading {nbpath}\")\n",
    "nb_resp = reqsess.get(f\"{api_base_url}/api/contents/{nbpath}\")\n",
    "file = nb_resp.json()\n",
    "\n",
    "nb_kernel_spec = file[\"content\"][\"metadata\"][\"kernelspec\"]\n",
    "nb_kernel_name = nb_kernel_spec[\"name\"]\n",
    "print(f\"Kernel spec:\\n{nb_kernel_spec}\\n\")\n",
    "\n",
    "code = [\n",
    "    c[\"source\"] for c in file[\"content\"][\"cells\"]\n",
    "    if c[\"cell_type\"] == \"code\" and len(c.get(\"source\", \"\")) > 0\n",
    "]\n",
    "print(f\"Loaded {len(code)} cells of code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-dover",
   "metadata": {},
   "source": [
    "## Initialise kernel and session\n",
    "\n",
    "To run the code, we'll need a **kernel** running and a **session** on that kernel.\n",
    "\n",
    "In SageMaker Studio, a kernel is specified by the combination of the kernel spec name (the container image URI) and the instance type to run it on.\n",
    "\n",
    "Although creating a kernel will automatically create an \"app\", deleting the kernel will not automatically clear the \"app\" because these concepts are not exactly equivalent through the APIs (see the clean-up section later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bearing-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found kernel spec!\n",
      "\n",
      "{'name': 'python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0', 'spec': {'argv': ['python3', '-m', 'IPython.kernel', '-f', '{connection_file}'], 'display_name': 'Python 3 (Data Science)', 'language': 'python', 'metadata': {'sme_metadata': {'environment_arn': 'arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0', 'display_name': 'Data Science', 'description': 'Anaconda Individual Edition https://www.anaconda.com/distribution/', 'gpu_optimized': False, 'is_template': True}, 'instance_type': 'ml.t3.medium'}}, 'resources': {'logo-64x64': '/kernelspecs/python3/logo-64x64.png', 'logo-32x32': '/kernelspecs/python3/logo-32x32.png'}}\n"
     ]
    }
   ],
   "source": [
    "kernel_specs = reqsess.get(f\"{api_base_url}/api/kernelspecs\").json()\n",
    "\n",
    "if nb_kernel_name in kernel_specs[\"kernelspecs\"]:\n",
    "    print(f\"Found kernel spec!\\n\")\n",
    "    print(kernel_specs[\"kernelspecs\"][nb_kernel_name])\n",
    "else:\n",
    "    print(json.dumps(kernel_specs, indent=2))\n",
    "    raise ValueError(f\"{nb_kernel_name} not present!\")\n",
    "    # TODO: Find closest spec if exact kernel spec is missing\n",
    "    # (This can happen when e.g. moving to different region, because the name of the kernelspec is the\n",
    "    # docker URI which is region-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "introductory-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 running kernels\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve currently running kernels:\n",
    "kernels = reqsess.get(f\"{api_base_url}/api/kernels\").json()\n",
    "print(f\"Found {len(kernels)} running kernels\\n\")\n",
    "print(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "familiar-explanation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO KERNEL ALREADY RUNNING: NEED TO CREATE\n"
     ]
    }
   ],
   "source": [
    "# Locate compatible kernel for notebook:\n",
    "try:\n",
    "    kernel = next(\n",
    "        k for k in kernels\n",
    "        if k[\"name\"] == nb_kernel_name\n",
    "        # TODO: instance type matches notebook spec or kernel default?\n",
    "    )\n",
    "    print(f\"Found compatible running kernel {kernel['id']}\")\n",
    "    print(kernel)\n",
    "except StopIteration:\n",
    "    kernel = None\n",
    "    print(f\"NO KERNEL ALREADY RUNNING: NEED TO CREATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "severe-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n",
      "Created kernel:\n",
      "{'id': '28b365d2-7bd7-4698-a8df-0764dcb348ee', 'name': 'python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0', 'last_activity': '2021-04-16T15:00:07.742703Z', 'execution_state': 'starting', 'connections': 0, 'instance_type': 'ml.t3.medium', 'app_name': 'datascience-1-0-ml-t3-medium-81187bd2ae843298bc309cb256a3'}\n"
     ]
    }
   ],
   "source": [
    "# Create a kernel if required:\n",
    "if kernel:\n",
    "    print(f\"Using existing kernel {kernel['id']}\")\n",
    "else:\n",
    "    print(f\"Creating kernel...\")\n",
    "    kernel_resp = reqsess.post(\n",
    "        f\"{api_base_url}/api/kernels\",\n",
    "        json={\n",
    "            \"name\": nb_kernel_name,\n",
    "            \"instance_type\": \"ml.t3.medium\",  # TODO: Take from NB metadata or default kernel spec or whatever\n",
    "            \"path\": nbpath,\n",
    "        },\n",
    "        params={ \"_xsrf\": reqsess.cookies[\"_xsrf\"] },  # Seems like this can be put in either header or query\n",
    "    )\n",
    "    # (If the SMStudio 'app' is not already created, this will just block until InService before returning)\n",
    "    print(kernel_resp)\n",
    "    kernel = kernel_resp.json()\n",
    "    print(f\"Created kernel:\\n{kernel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "settled-organic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '688bfe73-ae29-4a8f-b78c-0c445524a740',\n",
       " 'path': 'HelloWorld.ipynb-14a9785b-be56-4525-aaa6-b75ba1701ee3.ipynb',\n",
       " 'name': 'HelloWorld.ipynb',\n",
       " 'type': 'pending',\n",
       " 'kernel': {'id': '28b365d2-7bd7-4698-a8df-0764dcb348ee',\n",
       "  'name': 'python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0',\n",
       "  'last_activity': '2021-04-16T15:00:08.691402Z',\n",
       "  'execution_state': 'starting',\n",
       "  'connections': 0,\n",
       "  'instance_type': 'ml.t3.medium',\n",
       "  'app_name': 'datascience-1-0-ml-t3-medium-81187bd2ae843298bc309cb256a3'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a kernel session on the target kernel & notebook:\n",
    "nbsess_gen_uuid = uuid.uuid4()\n",
    "nbsess_resp = reqsess.post(\n",
    "    f\"{api_base_url}/api/sessions\",\n",
    "    json={\n",
    "        \"kernel\": {\n",
    "            \"id\": kernel[\"id\"],\n",
    "        },\n",
    "        # Attach a GUID to the path as SMStudio does (IDK, but needs it!)\n",
    "        \"path\": f\"{nbname}-{nbsess_gen_uuid}.ipynb\",\n",
    "        \"name\": nbname,\n",
    "        \"type\": \"pending\",  # ?\n",
    "    },\n",
    "    params={ \"_xsrf\": reqsess.cookies[\"_xsrf\"] },  # Seems like this can be put in either header or query\n",
    ")\n",
    "print(nbsess_resp)\n",
    "nbsess = nbsess_resp.json()\n",
    "nbsess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "encouraging-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '688bfe73-ae29-4a8f-b78c-0c445524a740',\n",
       " 'path': 'HelloWorld.ipynb-14a9785b-be56-4525-aaa6-b75ba1701ee3.ipynb',\n",
       " 'name': 'HelloWorld.ipynb',\n",
       " 'type': 'pending',\n",
       " 'kernel': {'id': '28b365d2-7bd7-4698-a8df-0764dcb348ee',\n",
       "  'name': 'python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0',\n",
       "  'last_activity': '2021-04-16T15:00:08.691402Z',\n",
       "  'execution_state': 'starting',\n",
       "  'connections': 0,\n",
       "  'instance_type': 'ml.t3.medium',\n",
       "  'app_name': 'datascience-1-0-ml-t3-medium-81187bd2ae843298bc309cb256a3'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Wait for execution_state?\n",
    "# ...It seems to say execution_state='starting' forever though...\n",
    "nbsess = reqsess.get(f\"{api_base_url}/api/sessions/{nbsess['id']}\").json()\n",
    "nbsess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-tennis",
   "metadata": {},
   "source": [
    "## Run the code\n",
    "\n",
    "You have the content you want to run, and a running kernel & session to do it on - we're finally ready to run the code!\n",
    "\n",
    "Actual communication with the session is via WebSocket APIs, rather than REST: So we'll first define some utility classes to smooth things along:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "composed-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JupyterWSMessageBase:\n",
    "    \"\"\"Utility class for composing a Jupyter WebSocket message object\"\"\"\n",
    "    def __init__(self, msg_type: str, session_id=None, user_id=\"dummyuser\", parent_msg=None):\n",
    "        self.msg_type = msg_type\n",
    "        self.parent_msg = parent_msg\n",
    "        self.session_id = session_id or uuid.uuid1().hex\n",
    "        self.user_id = user_id\n",
    "\n",
    "        self.msg_id = None\n",
    "        self.timestamp = None\n",
    "\n",
    "    def render(self):\n",
    "        self.msg_id = uuid.uuid1().hex\n",
    "        self.timestamp = datetime.now()\n",
    "        header = {\n",
    "            \"date\": self.timestamp.isoformat(),\n",
    "            \"msg_id\": self.msg_id,\n",
    "            \"msg_type\": self.msg_type,\n",
    "            \"session\": self.session_id,\n",
    "            \"username\": self.user_id,\n",
    "            \"version\": \"5.0\",\n",
    "        }\n",
    "        if self.parent_msg:\n",
    "            parent_header = {\n",
    "                \"date\": self.parent_msg.timestamp.isoformat(),\n",
    "                \"msg_id\": self.parent_msg.msg_id,\n",
    "                \"msg_type\": self.parent_msg.msg_type,\n",
    "                \"session\": self.parent_msg.session_id,\n",
    "                \"username\": self.parent_msg.user_id,\n",
    "                \"version\": \"5.0\",\n",
    "            }\n",
    "        else:\n",
    "            parent_header = {}\n",
    "        return {\n",
    "            \"header\": header,\n",
    "            \"parent_header\": parent_header,\n",
    "            \"metadata\": {},\n",
    "            \"content\": {},\n",
    "        }\n",
    "\n",
    "    def send(self, wsconn):\n",
    "        return wsconn.send(json.dumps(self.render()))\n",
    "\n",
    "class ExecuteCodeRequestMessage(JupyterWSMessageBase):\n",
    "    \"\"\"Utility class for composing a Jupyter WebSocket message to request execution of code on the kernel\"\"\"\n",
    "    def __init__(self, code, **kwargs):\n",
    "        super(ExecuteCodeRequestMessage, self).__init__(\"execute_request\", **kwargs)\n",
    "        self.code = code\n",
    "\n",
    "    def render(self):\n",
    "        base_msg = super(ExecuteCodeRequestMessage, self).render()\n",
    "        base_msg[\"content\"][\"code\"] = self.code\n",
    "        base_msg[\"content\"][\"silent\"] = False\n",
    "        return base_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-sleeve",
   "metadata": {},
   "source": [
    "Then to run through the notebook, simply:\n",
    "\n",
    "- Create a websocket connection, carrying over the required cookies from our REST session\n",
    "- Send requests to run each of the cells in turn\n",
    "- Wait for responses from the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rubber-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to:\n",
      "wss://d-ngfhxewhrmqe.studio.ap-southeast-1.sagemaker.aws/jupyter/default/api/kernels/28b365d2-7bd7-4698-a8df-0764dcb348ee/channels?session_id=688bfe73-ae29-4a8f-b78c-0c445524a740\n",
      "Connected\n",
      "\n",
      "Ignoring msg of type status\n",
      "Ignoring msg of type status\n",
      "Ignoring msg of type status\n",
      "Got cell response message of type status to cell 0\n",
      "Got cell response message of type execute_input to cell 0\n",
      "Got cell response message of type execute_reply to cell 0\n",
      "Cell 0 done\n",
      "Got cell response message of type status to cell 0\n",
      "Got cell response message of type status to cell 1\n",
      "Got cell response message of type execute_input to cell 1\n",
      "Got cell response message of type stream to cell 1\n",
      "Got cell response message of type status to cell 1\n",
      "Got cell response message of type execute_reply to cell 1\n",
      "Cell 1 done\n",
      "Got cell response message of type status to cell 2\n",
      "Got cell response message of type execute_input to cell 2\n",
      "Got cell response message of type execute_reply to cell 2\n",
      "Cell 2 done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Execution request/reply is done on websockets channels\n",
    "ws_base_url = \"wss://\" + api_base_url.partition(\"://\")[2] + \"/api/kernels\"\n",
    "cookies = reqsess.cookies.get_dict()\n",
    "\n",
    "print(f\"Connecting to:\\n{ws_base_url}/{kernel['id']}/channels?session_id={nbsess['id']}\")\n",
    "ws = websocket.create_connection(\n",
    "    f\"{ws_base_url}/{kernel['id']}/channels?session_id={nbsess['id']}\",\n",
    "    cookie=\"; \".join([\"%s=%s\" %(i, j) for i, j in cookies.items()]),\n",
    ")\n",
    "print(\"Connected\\n\")\n",
    "\n",
    "try:\n",
    "    # Send commands to \"Run all\", and build a store of req/responses:\n",
    "    cell_traffic = []\n",
    "    cell_traffic_by_req_id = {}\n",
    "    for ix, c in enumerate(code):\n",
    "        msg = ExecuteCodeRequestMessage(\n",
    "            code=c,\n",
    "            session_id=nbsess[\"id\"],\n",
    "        )\n",
    "        msg.send(ws)\n",
    "        cell_traffic_by_req_id[msg.msg_id] = {\n",
    "            \"cell_ix\": ix,\n",
    "            \"request\": msg,\n",
    "            \"responses\": [],\n",
    "        }\n",
    "        cell_traffic.append(cell_traffic_by_req_id[msg.msg_id])\n",
    "\n",
    "    # Read responses until we have 'em all':\n",
    "    cells_pending = [True for c in cell_traffic]\n",
    "    while any(cells_pending):\n",
    "        res = json.loads(ws.recv())\n",
    "        res_type = res[\"msg_type\"]\n",
    "        res_parent_id = res[\"parent_header\"].get(\"msg_id\")\n",
    "        if res_parent_id:\n",
    "            # Optional, maybe over-strict check - could just ignore these:\n",
    "            if not res_parent_id in cell_traffic_by_req_id:\n",
    "                raise ValueError(f\"Received 'reply' for unknown message ID:\\n{res}\")\n",
    "\n",
    "            cell_ix = cell_traffic_by_req_id[res_parent_id][\"cell_ix\"]\n",
    "            cell_traffic_by_req_id[res_parent_id][\"responses\"].append(res)\n",
    "            print(f\"Got cell response message of type {res_type} to cell {cell_ix}\")\n",
    "            if res_type == \"execute_reply\":\n",
    "                # Each cell execution request will typically generate a one or more 'status' messages,\n",
    "                # Zero or more 'stream' messages depending whether it has any output, and then a final\n",
    "                # 'execute_reply' message - signalling that it's done\n",
    "                cells_pending[cell_ix] = False\n",
    "                if res[\"content\"][\"status\"] != \"ok\":\n",
    "                    raise ValueError(f\"Cell {cell_ix} exited with status {res['status']}:\\n{res}\")\n",
    "                else:\n",
    "                    print(f\"Cell {cell_ix} done\")\n",
    "        else:\n",
    "            print(f\"Ignoring msg of type {res_type}\")\n",
    "    print(\"Done\")\n",
    "finally:\n",
    "    ws.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-whale",
   "metadata": {},
   "source": [
    "Optionally you can of course through the results of each cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "english-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'stdout', 'text': 'Hello, world!\\n'}\n"
     ]
    }
   ],
   "source": [
    "for ctraffic in cell_traffic:\n",
    "    for resp in ctraffic[\"responses\"]:\n",
    "        if resp[\"msg_type\"] == \"stream\":\n",
    "            print(resp[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-gibson",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "Of course when we're done we should clear up our session and kernel - and in particular, to release chargeable infrastructure, the SageMaker Studio \"App\" too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alike-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [204]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the session:\n",
    "del_sess_resp = reqsess.delete(\n",
    "    f\"{api_base_url}/api/sessions/{nbsess['id']}\",\n",
    "    params={ \"_xsrf\": reqsess.cookies[\"_xsrf\"] },\n",
    ")\n",
    "print(del_sess_resp)\n",
    "nbsess = None\n",
    "del_sess_resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "upset-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to run this?\n",
    "kernel = reqsess.post(\n",
    "    f\"{api_base_url}/api/kernels\",\n",
    "    json={\n",
    "        \"name\": nb_kernel_name,\n",
    "        \"instance_type\": \"ml.t3.medium\",  # TODO: Take from NB metadata or default kernel spec or whatever\n",
    "        \"path\": nbpath,\n",
    "    },\n",
    "    params={ \"_xsrf\": reqsess.cookies[\"_xsrf\"] },\n",
    ").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cleared-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting kernel c4d0e591-d6af-41ab-937b-95b3eb56179c...\n",
      "<Response [204]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the kernel:\n",
    "kernel_app_name = kernel[\"app_name\"]\n",
    "print(f\"Deleting kernel {kernel['id']}...\")\n",
    "del_kernel_resp = reqsess.delete(\n",
    "    f\"{api_base_url}/api/kernels/{kernel['id']}\",\n",
    "    params={ \"_xsrf\": reqsess.cookies[\"_xsrf\"] },\n",
    ")\n",
    "print(del_kernel_resp)\n",
    "kernel = None\n",
    "del_kernel_resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loved-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [204]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting the kernel does not automatically delete the 'app' - here's how:\n",
    "del_app_resp = reqsess.delete(\n",
    "    f\"{api_base_url}/sagemaker/api/apps/{kernel_app_name}\",\n",
    "    params={ \"_xsrf\": reqsess.cookies[\"_xsrf\"] },\n",
    ")\n",
    "print(del_app_resp)\n",
    "del_app_resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "amino-poster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the apps are gone:\n",
    "reqsess.get(f\"{api_base_url}/sagemaker/api/apps\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-watch",
   "metadata": {},
   "source": [
    "## All done!\n",
    "\n",
    "To extend into other use cases, you can refer to the Jupyter REST & client APIs mentioned earlier - and use browser network inspector/devtools to explore SageMaker extension APIs like the `apps` endpoint demonstrated here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
